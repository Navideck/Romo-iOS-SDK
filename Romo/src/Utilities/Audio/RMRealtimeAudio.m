//
//  RMRealtimeAudio.m
//  Romo
//
//  Created on 10/27/13.
//  Copyright (c) 2013 Romotive. All rights reserved.
//
//==============================================================================
// A graphical representation of the realtime audio pipeline
//
//  From
//  Mic   _________
// ----->|1 Remote |
//       |   I/O   |       ____________
//       |________0|----->|1           |       ________
//        _________       |    Mixer   |      | Effect |       _________
//       | Sampler |      |    Unit    |----->|  Unit  |----->|1 Remote |
//       |  Unit   |----->|0           |      |________|      |   I/O   |
//       |_________|      |____________|                      |________0|----->
//                                                                         To
//                                                                       Speaker
//==============================================================================
// The Remote I/O audio unit acts as both an input (mic capture) and as an
// output (rendering to speaker). At each of these stages, there is an input
// bus (0) and output bus (1).
//
// The mic samples come into Remote I/O on bus 1, and we get access to them
// through bus 0 in our recordingCallback. These same samples are sent to our
// playbackCallback (bus 1 of output), where they are either silenced (zeroed
// out) or replaced with a synthesized waveform generated by RMSynthesizer.
//
// The Sampler audio unit is for MIDI playback with a synthesized instrument.
// This unit can load "sound font" files as instruments and supports basic
// playback through RMSynthesizer convenience methods.
//
// The Remote I/O and Sampler units go into a Multi-Channel Mixer with two
// input channels. Each of these channels have separate gains and can be
// arbitrarily enabled and disabled.
//
// The Mixer feeds into an Effect unit, which applies a filter to the
// mixed output signal. This is the final waveform which will be sent to the
// speaker, again through the Remote I/O unit (but this time on bus 0 of
// the output).
//==============================================================================
#import "RMRealtimeAudio.h"

#import <RMShared/RMMath.h>
#import <RMShared/RMDispatchTimer.h>

#import "RMSoundEffect.h"

#ifdef SOUND_DEBUG
#define LOG(...) DDLogWarn(__VA_ARGS__)
#else
#define LOG(...)
#endif //SOUND_DEBUG

#define kDBOffset     -74.0
#define kLPFTimeSlice .007

#define kSampleRate 44100.0

#define kOutputBus  0
#define kInputBus   1

#define kMidiBus    0
#define kSynthBus   1

#define kFadeUpdateFrequency    20
#define kNumFades               5
#define kMaxGain                0.85
#define kMinGain                0.0

//==============================================================================
@interface RMRealtimeAudio ()
{
    AUGraph     _audioGraph;
    AudioUnit   _samplerUnit;
    AudioUnit   _effectUnit;
    AudioUnit   _mixerUnit;
    AudioUnit   _ioUnit;
    
    AudioStreamBasicDescription _audioFormat;
    AudioStreamBasicDescription _effectUnitDescription;
    AudioBufferList             _bufferList;
}

@property (nonatomic, readwrite, getter=isEnabled) BOOL enabled;

@property (nonatomic, strong) RMDispatchTimer *fader;
@property (nonatomic) int fadePosition;
@property (nonatomic) float fadeIncrement;

@property (atomic, readwrite, getter=isInterrupted) BOOL interrupted;

@end

//==============================================================================
@implementation RMRealtimeAudio

#pragma mark - Initialization / Teardown

// The shared instance to RMRealtimeAudio
//------------------------------------------------------------------------------
+ (RMRealtimeAudio *)sharedInstance
{
    static RMRealtimeAudio *sharedInstance = nil;
    static dispatch_once_t onceToken;
    dispatch_once(&onceToken, ^{
        sharedInstance = [[self alloc] init];
    });
    return sharedInstance;
}

// Set up some state - defaults with input
//------------------------------------------------------------------------------
- (id)init
{
    self = [super init];
    if (self) {
        LOG(@"Initializing: Start");

        // Set the default sample rate and fade state
        _sampleRate = kSampleRate;
        _state = RMFadeState_Idle;
        
        // Default state (both input and output disabled)
        _input  = NO;
        _output = NO;
        _enabled = NO;
        
        // Initialize the synth
        _synth = [[RMSynthesizer alloc] initWithAudio:self];
        
        [[NSNotificationCenter defaultCenter] addObserver:self
                                                 selector:@selector(handleApplicationWillEnterForegroundNotification:)
                                                     name:UIApplicationWillEnterForegroundNotification
                                                   object:nil];
        
        [[NSNotificationCenter defaultCenter] addObserver:self
                                                 selector:@selector(handleApplicationDidEnterBackgroundNotification:)
                                                     name:UIApplicationDidEnterBackgroundNotification
                                                   object:nil];
        
        [[NSNotificationCenter defaultCenter] addObserver:self
                                                 selector:@selector(handleApplicationDidBecomeActiveNotification:)
                                                     name:UIApplicationDidBecomeActiveNotification
                                                   object:nil];

        LOG(@"Initializing: Finish");
    }
    return self;
}

//------------------------------------------------------------------------------
- (void)dealloc
{
    [self shutdown];

    [[NSNotificationCenter defaultCenter] removeObserver:self];
}

#pragma mark - Public Methods

// Starts up realtime audio
//------------------------------------------------------------------------------
- (void)startup
{
    dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0), ^{
        if (!self.enabled) {
            LOG(@"Starting up");
            [RMSoundEffect startup];
            [self createAUGraph];
            [self setupAudioUnits];
            self.interrupted = NO;
            LOG(@"Successfully started");
        }
    });
}

// Shuts down realtime audio
//------------------------------------------------------------------------------
- (void)shutdown
{
    if (self.enabled) {
        LOG(@"Shutting down");
        [RMSoundEffect shutdown];
        [self teardownAudioUnits];
        LOG(@"Successfully shut down");
    }
}

#pragma mark - Notifications
//------------------------------------------------------------------------------
- (void)handleApplicationWillEnterForegroundNotification:(NSNotification *)notification
{
    LOG(@"Entering foreground");
    [self startup];
}

//------------------------------------------------------------------------------
- (void)handleApplicationDidEnterBackgroundNotification:(NSNotification *)notification
{
    LOG(@"Entering background");
    [self shutdown];
}

//------------------------------------------------------------------------------
- (void)handleApplicationDidBecomeActiveNotification:(NSNotification *)notification
{
    if (self.isInterrupted) {
        LOG(@"Became active in interrupted state");
        [self shutdown];
        [self startup];
    }
}

#pragma mark - AudioUnit Initialization / Teardown
// Creates the AudioGraph
//------------------------------------------------------------------------------
- (BOOL)createAUGraph
{
	OSStatus result = noErr;
    
    // Create a new AUGraph
	result = NewAUGraph(&_audioGraph);
    checkStatus(result);
    
    // Set up the nodes for the graph
    // The sampler node and ioNode (input) connect to the mixer node,
    // which outputs to the mixer node, which connects back to the ioUnit (output)
	AUNode effectNode, mixerNode, ioNode;
    
	// Description of the Sampler Unit
//    AudioComponentDescription samplerUnitDescription;
//	samplerUnitDescription.componentManufacturer     = kAudioUnitManufacturer_Apple;
//	samplerUnitDescription.componentFlags            = 0;
//	samplerUnitDescription.componentFlagsMask        = 0;
//	samplerUnitDescription.componentType             = kAudioUnitType_MusicDevice;
//	samplerUnitDescription.componentSubType          = kAudioUnitSubType_Sampler;
//	
//    // Add the Sampler unit node to the graph
//	result = AUGraphAddNode(_audioGraph, &samplerUnitDescription, &samplerNode);
//    checkStatus(result);
    
    // Description of the Effect unit
    AudioComponentDescription effectUnitDescription;
    effectUnitDescription.componentManufacturer = kAudioUnitManufacturer_Apple;
    effectUnitDescription.componentFlags        = 0;
    effectUnitDescription.componentFlagsMask    = 0;
    effectUnitDescription.componentType         = kAudioUnitType_Effect;
    effectUnitDescription.componentSubType      = kAudioUnitSubType_BandPassFilter;
    
    // Add the Effect unit node to the graph
    result = AUGraphAddNode(_audioGraph, &effectUnitDescription, &effectNode);
    checkStatus(result);
    
    // Description of the Mixer Unit
    AudioComponentDescription mixerUnitDescription;
    mixerUnitDescription.componentManufacturer  = kAudioUnitManufacturer_Apple;
    mixerUnitDescription.componentFlags         = 0;
    mixerUnitDescription.componentFlagsMask     = 0;
    mixerUnitDescription.componentType          = kAudioUnitType_Mixer;
    mixerUnitDescription.componentSubType       = kAudioUnitSubType_MultiChannelMixer;
    
    // Add the Mixer unit node to the graph
    result = AUGraphAddNode(_audioGraph, &mixerUnitDescription, &mixerNode);
    checkStatus(result);
    
	// Specify the Output unit, to be used as the second and final node of the graph
    AudioComponentDescription ioUnitDescription;
	ioUnitDescription.componentManufacturer     = kAudioUnitManufacturer_Apple;
	ioUnitDescription.componentFlags            = 0;
	ioUnitDescription.componentFlagsMask        = 0;
	ioUnitDescription.componentType             = kAudioUnitType_Output;
	ioUnitDescription.componentSubType          = kAudioUnitSubType_RemoteIO;
    
    // Add the Output unit node to the graph
	result = AUGraphAddNode(_audioGraph, &ioUnitDescription, &ioNode);
    checkStatus(result);
    
    // Open the graph
	result = AUGraphOpen(_audioGraph);
    checkStatus(result);
    
	// Obtain a reference to the Sampler unit
//	result = AUGraphNodeInfo(_audioGraph, samplerNode, 0, &_samplerUnit);
//    checkStatus(result);
    
    // Obtain a reference to the Mixer unit
    result = AUGraphNodeInfo(_audioGraph, mixerNode, 0, &_mixerUnit);
    checkStatus(result);
    
    // Obtain a reference to the Effect unit
	result = AUGraphNodeInfo(_audioGraph, effectNode, 0, &_effectUnit);
    checkStatus(result);
    
	// Obtain a reference to the Remote I/O unit
	result = AUGraphNodeInfo(_audioGraph, ioNode, 0, &_ioUnit);
    checkStatus(result);
    
    // Connect all of the nodes and set up the mixer unit
    /////////////////////////////////////////////////////
    
    // Set the bus count - we need two channels going into the mixer
    //  ...one for the sampler unit, and one for our callback function
//    UInt32 busCount = 2;
//    result = AudioUnitSetProperty(_mixerUnit, kAudioUnitProperty_ElementCount, kAudioUnitScope_Input, 0, &busCount, sizeof(busCount));

    // Define the format going into the mixer for each channel
    _audioFormat.mSampleRate = self.sampleRate;
    _audioFormat.mFormatID = kAudioFormatLinearPCM;
    _audioFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked;
    _audioFormat.mFramesPerPacket = 1;
    _audioFormat.mChannelsPerFrame = 1;
    _audioFormat.mBitsPerChannel = 16;
    _audioFormat.mBytesPerPacket = 2;
    _audioFormat.mBytesPerFrame = 2;
    
    result = AudioUnitSetProperty(_mixerUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input, 0, &_audioFormat, sizeof(_audioFormat));
    checkStatus(result);
    
    result = AudioUnitSetProperty(_mixerUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input, 1, &_audioFormat, sizeof (_audioFormat));
    checkStatus(result);
    
    // Connect the nodes
//    result = AUGraphConnectNodeInput(_audioGraph, samplerNode, 0, mixerNode, 0);
//    checkStatus(result);
    result = AUGraphConnectNodeInput(_audioGraph, mixerNode, 0, effectNode, 0);
    checkStatus(result);
	result = AUGraphConnectNodeInput (_audioGraph, effectNode, 0, ioNode, 0);
    checkStatus(result);
    
    // Attach the input render callback and context to each input bus
    // Setup the struture that contains the input render callback
    AURenderCallbackStruct inputCallbackStruct;
    inputCallbackStruct.inputProc        = &playbackCallback;
    inputCallbackStruct.inputProcRefCon  = (__bridge void*) self;
    
    // Set a callback for the specified node's specified input
    result = AUGraphSetNodeInputCallback(_audioGraph, mixerNode, 1, &inputCallbackStruct);
    checkStatus(result);
    
    return YES;
}

//------------------------------------------------------------------------------
- (void)setupAudioUnits
{
    // Initialize Audio Session
    OSStatus status;
    static dispatch_once_t onceToken;
    dispatch_once(&onceToken, ^{
        OSStatus status = AudioSessionInitialize(NULL, NULL, interruptionListener, (__bridge void*) self);
        checkStatus(status);
    });
    
    // Setup the Remote I/O unit for recording (not in the AUGraph)
    // Enable IO for recording
    UInt32 flag = 1;
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioOutputUnitProperty_EnableIO,
                                  kAudioUnitScope_Input,
                                  kInputBus,
                                  &flag,
                                  sizeof(flag));
    checkStatus(status);
    
    // Apply format to both the input and output channels
    
    // Scope is set to output because we want to change the format as the audio
    // signal comes OUT of the microphone and into our callback function
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioUnitProperty_StreamFormat,
                                  kAudioUnitScope_Output,
                                  kInputBus,
                                  &_audioFormat,
                                  sizeof(_audioFormat));
    checkStatus(status);
    
    // Scope is set to input because we want to change the format as the audio signal
    // leaves our callback and goes INTO the speaker)
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioUnitProperty_StreamFormat,
                                  kAudioUnitScope_Input,
                                  kOutputBus,
                                  &_audioFormat,
                                  sizeof(_audioFormat));
    checkStatus(status);
    
    // Set input callback - used for recording
    AURenderCallbackStruct callbackStruct;
    callbackStruct.inputProc = recordingCallback;
    callbackStruct.inputProcRefCon = (__bridge void*)self;
    
    // Set output callback - used for synthesis/playback.
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioOutputUnitProperty_SetInputCallback,
                                  kAudioUnitScope_Global,
                                  kInputBus,
                                  &callbackStruct,
                                  sizeof(callbackStruct));
    checkStatus(status);
    
    // Disable buffer allocation for the recorder
    flag = 0;
    status = AudioUnitSetProperty(_ioUnit, kAudioUnitProperty_ShouldAllocateBuffer, kAudioUnitScope_Output, kInputBus, &flag, sizeof(flag));
    checkStatus(status);
    
    // Set the audio session
    UInt32 category = kAudioSessionCategory_PlayAndRecord;
    status = AudioSessionSetProperty(kAudioSessionProperty_AudioCategory, sizeof(category), &category);
    checkStatus(status);

    // Use the device's primary microphone
    // Note - this also causes all audio output to have less processing, resulting in much quieter sounds
//    UInt32 sessionMode = kAudioSessionMode_Measurement;
//    status = AudioSessionSetProperty(kAudioSessionProperty_Mode, sizeof (sessionMode), &sessionMode);
//    checkStatus(status);
    
    // Set the sample rate of the AUSampler unit
    float samplerRate = self.sampleRate;
//    status = AudioUnitSetProperty(_samplerUnit, kAudioUnitProperty_SampleRate, kAudioUnitScope_Output, 0, &samplerRate, sizeof(samplerRate));
//    checkStatus(status); // CRASH (status = -10851)
    
    // Set FramesPerSlice to 0 so the device decides
    UInt32 framesPerSlice = 0;
    UInt32 framesPerSlicePropertySize = sizeof(framesPerSlice);
    status = AudioUnitGetProperty(_ioUnit, kAudioUnitProperty_MaximumFramesPerSlice, kAudioUnitScope_Global, 0, &framesPerSlice, &framesPerSlicePropertySize);
    checkStatus(status);
    
    // Do the same for the sampler unit
//    status = AudioUnitSetProperty(_samplerUnit, kAudioUnitProperty_MaximumFramesPerSlice, kAudioUnitScope_Global, 0, &framesPerSlice, framesPerSlicePropertySize);
//    checkStatus(status);
    
    // Set up the effects unit
    UInt32 asbdSize = sizeof(_effectUnitDescription);
	memset (&_effectUnitDescription, 0, sizeof(_effectUnitDescription));
	status = AudioUnitGetProperty(_effectUnit,
                                  kAudioUnitProperty_StreamFormat,
                                  kAudioUnitScope_Input,
                                  0,
                                  &_effectUnitDescription,
                                  &asbdSize);
    checkStatus(status);
	
    //    [self printASBD:_effectUnitDescription];
    _effectUnitDescription.mSampleRate = samplerRate;      // make sure the sample rate is correct
    
    // now set this asbd to the effect unit input scope
    // note: if the asbd sample rate is already equal to graphsamplerate then this next statement is not
    // necessary because we derived the asbd from what it was already set to.
	status = AudioUnitSetProperty(_effectUnit,
                                  kAudioUnitProperty_StreamFormat,
                                  kAudioUnitScope_Input,
                                  0,
                                  &_effectUnitDescription,
                                  sizeof(_effectUnitDescription));
    checkStatus(status);
    
//    // Set the mixer unit's output sample rate format. This is the only aspect of the output stream
//    //    format that must be explicitly set.
//    status = AudioUnitSetProperty(_mixerUnit,
//                                  kAudioUnitProperty_SampleRate,
//                                  kAudioUnitScope_Output,
//                                  0,
//                                  &samplerRate,
//                                  sizeof(samplerRate));
//    checkStatus(status); // CRASH (status = -10851)
    
    // and finally... set our new effect stream format on the output scope of the mixer.
    // app will blow up at runtime without this
    status = AudioUnitSetProperty(_mixerUnit,
                                  kAudioUnitProperty_StreamFormat,
                                  kAudioUnitScope_Output,
                                  0,
                                  &_effectUnitDescription,
                                  sizeof(_effectUnitDescription));
    checkStatus(status);
    
    // Check that the
    if (_audioGraph) {
        // Initialize and Start
        status = AUGraphInitialize(_audioGraph);
        checkStatus(status);
        status = AUGraphStart(_audioGraph);
        checkStatus(status);
        
        // Printing the graph gives you some information in the output console.
#ifdef SOUND_DEBUG
        CAShow(_audioGraph);
#endif
    }
    
    // Set the session to be active
    status = AudioSessionSetActive(YES);
    checkStatus(status);
    
    // Route the audio to the speaker
    routeAudioToSpeaker(NULL, 0, 0, NULL);
    status = AudioSessionAddPropertyListener(kAudioSessionProperty_AudioRouteChange, routeAudioToSpeaker, nil);
    checkStatus(status);
    
    // Initialize the Remote IO unit
    status = AudioUnitInitialize(_ioUnit);
    checkStatus(status);
    
    // Start the effects
	status = AudioUnitSetParameter(_effectUnit,
                                   kBandpassParam_CenterFrequency,
                                   kAudioUnitScope_Global,
                                   0,
                                   300,
                                   0);
    checkStatus(status);
    
    status = AudioUnitSetParameter(_effectUnit,
                                   kBandpassParam_Bandwidth,
                                   kAudioUnitScope_Global,
                                   0,
                                   100,
                                   0);
    checkStatus(status);
    
    // Configure the Mixer
    //      It's easier to imagine a large mixing board with the following lines of code.
    //      Each channel has an input bus, it is either on or off, and has a gain.
    //      ...and the whole board has a main slider for the output gain)
    [self enableMixerInput:kMidiBus isOn:NO];
    [self enableMixerInput:kSynthBus isOn:YES];
    
    [self setMixerOutputGain:kMinGain];
    
    [self setMixerInput:kMidiBus gain:kMinGain];
    [self setMixerInput:kSynthBus gain:kMaxGain];
    
    //    [self loadFromDLSOrSoundFontName:@"Claudio_Piano" withPatch:0];
    self.enabled = YES;
}

//------------------------------------------------------------------------------
void routeAudioToSpeaker(void                   *inUserData,
                         AudioSessionPropertyID inPropertyID,
                         UInt32                 inPropertyValueSize,
                         const void             *inPropertyValue)
{
    UInt32 mixWithOthers = YES;
    AudioSessionSetProperty(kAudioSessionProperty_OverrideCategoryMixWithOthers, sizeof(mixWithOthers), &mixWithOthers);
    
    UInt32 audioRouteOverride = kAudioSessionOverrideAudioRoute_Speaker;
    AudioSessionSetProperty(kAudioSessionProperty_OverrideAudioRoute, sizeof(audioRouteOverride), &audioRouteOverride);
}

//------------------------------------------------------------------------------
- (void)teardownAudioUnits
{
    LOG(@"Tearing down audio units...");
    self.enabled = NO;
    [_fader stopRunning];
    [self.synth.lfoTimer stopRunning];
    
    if (_audioGraph) {
        OSStatus status = AUGraphStop(_audioGraph);
        checkStatus(status);
        
        status = DisposeAUGraph(_audioGraph);
        checkStatus(status);
    }
    LOG(@"Finished tearing down audio units");
}

#pragma mark - AudioUnit callbacks

// Handler that is called when we get an audio interrupt
//------------------------------------------------------------------------------
void interruptionListener(void      *inRefCon,
                          UInt32    inInterruptionState)
{
    RMRealtimeAudio *me = (__bridge RMRealtimeAudio *)inRefCon;
    // Flag that we need to start up again
    if (inInterruptionState == kAudioSessionBeginInterruption) {
#ifdef SOUND_DEBUG
        printf("\n\nRMRealtimeAudio: Begin interruption\n\n");
#endif
        me.interrupted = YES;
        
        OSStatus status = AudioSessionSetActive(NO);
        checkStatus(status);
    }
    // Let's start things back up...
    else if ((inInterruptionState == kAudioSessionEndInterruption) && me.interrupted) {
#ifdef SOUND_DEBUG
        printf("\n\nRMRealtimeAudio: End interruption\n\n");
#endif
        me.interrupted = NO;
        [me shutdown];
        [me startup];
    }
}

// This function alerts you that the newest input samples are available and you
//  should call AudioUnitRender to do stuff with them
//------------------------------------------------------------------------------
static OSStatus recordingCallback(void                          *inRefCon,
                                  AudioUnitRenderActionFlags    *ioActionFlags,
                                  const AudioTimeStamp          *inTimeStamp,
                                  UInt32 						inBusNumber,
                                  UInt32 						inNumberFrames,
                                  AudioBufferList               *ioData)
{
    RMRealtimeAudio *me = (__bridge RMRealtimeAudio *)inRefCon;
    
    if (!me.input) {
        return noErr;
    }
    
    me->_bufferList.mNumberBuffers = 1;
    me->_bufferList.mBuffers[0].mDataByteSize = sizeof(SInt16)*inNumberFrames;
    me->_bufferList.mBuffers[0].mNumberChannels = 1;
    me->_bufferList.mBuffers[0].mData = (SInt16 *) malloc(sizeof(SInt16)*inNumberFrames);
    
    OSStatus status;
    status = AudioUnitRender(me->_ioUnit, ioActionFlags, inTimeStamp, inBusNumber, inNumberFrames, &(me->_bufferList));
    checkStatus(status);
    
    dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0), ^{
        [me processInputSamples:(SInt16*)me->_bufferList.mBuffers[0].mData
                     withLength:inNumberFrames];
    });
    
    return noErr;
}

// This function asks you to produce a "inNumberFrames" amount of samples and
//  place them in ioData, they will soon be played by the speaker
//------------------------------------------------------------------------------
static OSStatus playbackCallback(void                       *inRefCon,
                                 AudioUnitRenderActionFlags *ioActionFlags,
                                 const AudioTimeStamp 		*inTimeStamp,
                                 UInt32 					inBusNumber,
                                 UInt32 					inNumberFrames,
                                 AudioBufferList 			*ioData)
{
    RMRealtimeAudio *me = (__bridge RMRealtimeAudio *)inRefCon;
    SInt16 *temp = (SInt16 *)ioData->mBuffers[0].mData;
    
    if (!me.output || !me.synth || !me.synth.playing) {
        memset(temp, 0, inNumberFrames*sizeof(SInt16));
    } else {
        [me.synth synthesizeSamples:temp withLength:inNumberFrames];
    }
    
    return noErr;
}

//------------------------------------------------------------------------------
- (void)processInputSamples:(SInt16 *)samples
                 withLength:(int)length
{
    // Calculate Decibel level
    //////////////////////////
    Float32 decibels = kDBOffset; // If there's no signal, set to lowest value
    
    static BOOL firstRun = YES;
    
    Float32 currentFilteredValueOfSampleAmplitude = 0;
    static Float32 previousFilteredValueOfSampleAmplitude = 0;
    Float32 peakValue = kDBOffset;
    
    // Run through each sample in the buffer
    for (int i = 0; i < length; i++) {
        Float32 absoluteValueOfSampleAmplitude = abs(samples[i]);
        
        // If we're on the very first run, use the first sample
        if (firstRun) {
            currentFilteredValueOfSampleAmplitude = absoluteValueOfSampleAmplitude;
            firstRun = NO;
        }
        // For each sample's absolute value, run it through a simple low-pass filter
        else {
            currentFilteredValueOfSampleAmplitude = kLPFTimeSlice * absoluteValueOfSampleAmplitude + (1.0 - kLPFTimeSlice) * previousFilteredValueOfSampleAmplitude;
        }
        
        previousFilteredValueOfSampleAmplitude = currentFilteredValueOfSampleAmplitude;
        Float32 amplitudeToConvertToDB = currentFilteredValueOfSampleAmplitude;
        
        //        DDLogInfo(@",%f,%f,", absoluteValueOfSampleAmplitude, currentFilteredValueOfSampleAmplitude);
        
        // For each sample's filtered absolute value, convert it into decibels
        // We add the offset value to normalize the clipping point of the device to 0 dB
        Float32 sampleDB = 20.0*log10(amplitudeToConvertToDB) + kDBOffset;
        
        // Check if it's a rational number and isn't infinite
        if ((sampleDB == sampleDB) && (sampleDB != -DBL_MAX)) {
            // Keep it if it's the peak value of this sample buffer
            if (sampleDB > peakValue) {
                peakValue = sampleDB;
            }
            decibels = peakValue;
        }
    }
    
    if ([self.delegate respondsToSelector:@selector(gotDecibelLevel:)]) {
        [self.delegate gotDecibelLevel:decibels];
    }
    
    if (decibels > -20) {
        if ([self.delegate respondsToSelector:@selector(lineLevelActivated)]) {
            [self.delegate lineLevelActivated];
        }
    } else if (decibels < -50) {
        if ([self.delegate respondsToSelector:@selector(lineLevelDeactivated)]) {
            [self.delegate lineLevelDeactivated];
        }
    }
    
    if ([self.delegate respondsToSelector:@selector(didReceiveSampleBufferFromMic:withLength:)]) {
        [self.delegate didReceiveSampleBufferFromMic:samples
                                          withLength:length];
    }
}

#pragma mark - Effects helpers
//------------------------------------------------------------------------------
- (void)setEffectsEnabled:(BOOL)effectsEnabled
{
    if (_effectsEnabled != effectsEnabled) {
        _effectsEnabled = effectsEnabled;
        UInt32 bypassed = effectsEnabled;
        OSStatus status = AudioUnitSetProperty(_effectUnit,
                                               kAudioUnitProperty_BypassEffect,
                                               kAudioUnitScope_Global,
                                               0,
                                               &bypassed,
                                               sizeof(bypassed));
        checkStatus(status);
    }
}

//------------------------------------------------------------------------------
- (void)setEffectPosition:(float)effectPosition
{
    if (_effectPosition != effectPosition) {
        _effectPosition = effectPosition;
        
        float mappedEffect = [RMMath map:_effectPosition min:0.0 max:1.0 out_min:40 out_max:11000];
        OSStatus status = AudioUnitSetParameter(_effectUnit,
                                                kBandpassParam_Bandwidth,
                                                kAudioUnitScope_Global,
                                                0,
                                                mappedEffect,
                                                0);
        checkStatus(status);
    }
}

#pragma mark - Mixer unit
// Enable or disable a specified bus
//------------------------------------------------------------------------------
- (void)enableMixerInput:(UInt32)inputBus
                    isOn:(AudioUnitParameterValue)isOnValue
{
    OSStatus result = AudioUnitSetParameter(_mixerUnit,
                                            kMultiChannelMixerParam_Enable,
                                            kAudioUnitScope_Input,
                                            inputBus,
                                            isOnValue,
                                            0);
    checkStatus(result);
}

// Set the mixer unit input volume for a specified bus
//------------------------------------------------------------------------------
- (void)setMixerInput:(UInt32)inputBus
                 gain:(AudioUnitParameterValue)newGain
{
    OSStatus result = AudioUnitSetParameter(_mixerUnit,
                                            kMultiChannelMixerParam_Volume,
                                            kAudioUnitScope_Input,
                                            inputBus,
                                            newGain,
                                            0);
    checkStatus(result);
}

// Get the mixer unit input volume for a specified bus
//------------------------------------------------------------------------------
- (float)getMixerInputGainForBus:(UInt32)inputBus
{
    float gain;
    OSStatus result = AudioUnitGetParameter(_mixerUnit,
                                            kMultiChannelMixerParam_Volume,
                                            kAudioUnitScope_Input,
                                            inputBus,
                                            &gain);
    checkStatus(result);
    return gain;
}

// Set the mxer unit output volume
//------------------------------------------------------------------------------
- (void)setMixerOutputGain:(AudioUnitParameterValue)newGain
{
    OSStatus result = AudioUnitSetParameter(_mixerUnit,
                                            kMultiChannelMixerParam_Volume,
                                            kAudioUnitScope_Output,
                                            0,
                                            newGain,
                                            0);
    checkStatus(result);
}

// Get the mxer unit output volume
//------------------------------------------------------------------------------
- (float)getMixerOutputGain
{
    float gain;
    OSStatus result = AudioUnitGetParameter(_mixerUnit,
                                            kMultiChannelMixerParam_Volume,
                                            kAudioUnitScope_Output,
                                            0,
                                            &gain);
    checkStatus(result);
    return gain;
}

//------------------------------------------------------------------------------
- (void)setState:(RMFadeState)state
{
    if (_state != state) {
        _state = state;
        
        self.fadePosition = 0;
        self.fadeIncrement = 0.0;
        
        switch (_state) {
            case RMFadeState_FadeIn:
                self.synth.playing = YES;
                self.fadeIncrement = (kMaxGain - [self getMixerOutputGain]) / kNumFades;
                if (self.fadeIncrement > 0.0) {
                    [self.fader startRunning];
                } else {
                    [self setMixerOutputGain:kMaxGain];
                    _state = RMFadeState_Sustain;
                }
                break;
            case RMFadeState_FadeOut:
                self.fadeIncrement = (kMinGain - [self getMixerOutputGain]) / kNumFades;
                if (self.fadeIncrement < 0.0) {
                    [self.fader startRunning];
                } else {
                    [self setMixerOutputGain:kMinGain];
                    _state = RMFadeState_Idle;
                    self.synth.playing = NO;
                }
                break;
            case RMFadeState_Idle:
                [self setMixerOutputGain:kMinGain];
                [self.fader stopRunning];
                self.synth.playing = NO;
                break;
            case RMFadeState_Sustain:
                self.synth.playing = YES;
                [self setMixerOutputGain:kMaxGain];
                [self.fader stopRunning];
                break;
        }
    }
}

//------------------------------------------------------------------------------
- (RMDispatchTimer *)fader
{
    if (!_fader) {
        _fader = [[RMDispatchTimer alloc] initWithName:@"com.romotive.audio.fade"
                                             frequency:kFadeUpdateFrequency];
        __weak RMRealtimeAudio *weakSelf = self;
        
        _fader.eventHandler = ^{
            [weakSelf updateFade];
        };
    }
    return _fader;
}

//------------------------------------------------------------------------------
- (void)updateFade
{
    float currentGain = [self getMixerOutputGain];
    int numFadesLeft = kNumFades - self.fadePosition;
    
    switch (self.state) {
        case RMFadeState_FadeIn:
            if (numFadesLeft > 1 && currentGain < kMaxGain) {
                float newGain = currentGain + self.fadeIncrement;
                [self setMixerOutputGain:newGain];
            } else {
                self.state = RMFadeState_Sustain;
            }
            break;
        case RMFadeState_FadeOut:
            if (numFadesLeft > 1 && currentGain > .01f) {
                float newGain = currentGain + self.fadeIncrement;
                [self setMixerOutputGain:newGain];
            } else {
                self.state = RMFadeState_Idle;
            }
            break;
        case RMFadeState_Idle:
        case RMFadeState_Sustain:
        default:
            [self.fader stopRunning];
            break;
    }
    
    self.fadePosition++;
}

#pragma mark - MIDI helpers
//------------------------------------------------------------------------------
- (void)executeMidiCommand:(UInt32)command
                  withNote:(UInt32)note
              withVelocity:(UInt32)velocity
{
    if (_samplerUnit) {
        OSStatus result = noErr;
        result = MusicDeviceMIDIEvent(_samplerUnit, command, note, velocity, 0);
        checkStatus(result);
    }
}

#pragma mark - Helpers
// Helper method for checking status of an AudioUnit call
//------------------------------------------------------------------------------
void checkStatus(OSStatus status)
{
    if (status != 0) {
#ifdef SOUND_DEBUG
        NSLog(@"ERROR (AudioUnit): %@\n", [RMRealtimeAudio stringFromErrorCode:status]);
#endif
    }
}

// Tries to print out a helpful error code (but seldom does)
//------------------------------------------------------------------------------
+ (NSString *)stringFromErrorCode:(OSStatus)status
{
    switch (status) {
        case kAudioFileUnspecifiedError:
            return @"kAudioFileUnspecifiedError";
        case kAudioFileUnsupportedFileTypeError:
            return @"kAudioFileUnsupportedFileTypeError";
        case kAudioFileUnsupportedDataFormatError:
            return @"kAudioFileUnsupportedDataFormatError";
        case kAudioFileUnsupportedPropertyError:
            return @"kAudioFileUnsupportedPropertyError";
        case kAudioFileBadPropertySizeError:
            return @"kAudioFileBadPropertySizeError";
        case kAudioFilePermissionsError:
            return @"kAudioFilePermissionsError";
        case kAudioFileNotOptimizedError:
            return @"kAudioFileNotOptimizedError";
        case kAudioFileInvalidChunkError:
            return @"kAudioFileInvalidChunkError";
        case kAudioFileDoesNotAllow64BitDataSizeError:
            return @"kAudioFileDoesNotAllow64BitDataSizeError";
        case kAudioFileInvalidPacketOffsetError:
            return @"kAudioFileInvalidPacketOffsetError";
        case kAudioFileInvalidFileError:
            return @"kAudioFileInvalidFileError";
        case kAudioFileOperationNotSupportedError:
            return @"kAudioFileOperationNotSupportedError";
        case kAudioFileNotOpenError:
            return @"kAudioFileNotOpenError";
        case kAudioFileEndOfFileError:
            return @"kAudioFileEndOfFileError";
        case kAudioFilePositionError:
            return @"kAudioFilePositionError";
        case kAudioFileFileNotFoundError:
            return @"kAudioFileFileNotFoundError";
        case kAudioUnitErr_InvalidProperty:
            return @"kAudioUnitErr_InvalidProperty";
        case kAudioUnitErr_InvalidParameter:
            return @"kAudioUnitErr_InvalidParameter";
        case kAudioUnitErr_InvalidElement:
            return @"kAudioUnitErr_InvalidElement";
        case kAudioUnitErr_NoConnection:
            return @"kAudioUnitErr_NoConnection";
        case kAudioUnitErr_FailedInitialization:
            return @"kAudioUnitErr_FailedInitialization";
        case kAudioUnitErr_TooManyFramesToProcess:
            return @"kAudioUnitErr_TooManyFramesToProcess";
        case kAudioUnitErr_IllegalInstrument:
            return @"kAudioUnitErr_IllegalInstrument";
        case kAudioUnitErr_InstrumentTypeNotFound:
            return @"kAudioUnitErr_InstrumentTypeNotFound";
        case kAudioUnitErr_InvalidFile:
            return @"kAudioUnitErr_InvalidFile";
        case kAudioUnitErr_UnknownFileType:
            return @"kAudioUnitErr_UnknownFileType";
        case kAudioUnitErr_FileNotSpecified:
            return @"kAudioUnitErr_FileNotSpecified";
        case kAudioUnitErr_FormatNotSupported:
            return @"kAudioUnitErr_FormatNotSupported";
        case kAudioUnitErr_Uninitialized:
            return @"kAudioUnitErr_Uninitialized";
        case kAudioUnitErr_InvalidScope:
            return @"kAudioUnitErr_InvalidScope";
        case kAudioUnitErr_PropertyNotWritable:
            return @"kAudioUnitErr_PropertyNotWritable";
        case kAudioUnitErr_CannotDoInCurrentContext:
            return @"kAudioUnitErr_CannotDoInCurrentContext";
        case kAudioUnitErr_InvalidPropertyValue:
            return @"kAudioUnitErr_InvalidPropertyValue";
        case kAudioUnitErr_PropertyNotInUse:
            return @"kAudioUnitErr_PropertyNotInUse";
        case kAudioUnitErr_Initialized:
            return @"kAudioUnitErr_Initialized";
        case kAudioUnitErr_InvalidOfflineRender:
            return @"kAudioUnitErr_InvalidOfflineRender";
        case kAudioUnitErr_Unauthorized:
            return @"kAudioUnitErr_Unauthorized";
        case kAUGraphErr_NodeNotFound:
            return @"kAUGraphErr_NodeNotFound";
        case kAUGraphErr_InvalidConnection:
            return @"kAUGraphErr_InvalidConnection";
        case kAUGraphErr_OutputNodeErr:
            return @"kAUGraphErr_OutputNodeErr";
        case kAUGraphErr_InvalidAudioUnit:
            return @"kAUGraphErr_InvalidAudioUnit";
        default:
            return @"unknown error";
    }
}

// Helpful for looking at the fields of an AudioStreamBasicDescription struct
//------------------------------------------------------------------------------
- (void)printASBD:(AudioStreamBasicDescription)asbd
{
    char formatIDString[5];
    UInt32 formatID = CFSwapInt32HostToBig (asbd.mFormatID);
    bcopy (&formatID, formatIDString, 4);
    formatIDString[4] = '\0';

    LOG(@"  Sample Rate:         %10.0f",    asbd.mSampleRate);
    LOG(@"  Format ID:           %10s",      formatIDString);
    LOG(@"  Format Flags:        %10lu",     asbd.mFormatFlags);
    LOG(@"  Bytes per Packet:    %10lu",     asbd.mBytesPerPacket);
    LOG(@"  Frames per Packet:   %10lu",     asbd.mFramesPerPacket);
    LOG(@"  Bytes per Frame:     %10lu",     asbd.mBytesPerFrame);
    LOG(@"  Channels per Frame:  %10lu",     asbd.mChannelsPerFrame);
    LOG(@"  Bits per Channel:    %10lu",     asbd.mBitsPerChannel);
}

// A convenient way to silence a sample of audio
//------------------------------------------------------------------------------
void silenceData(AudioBufferList *inData)
{
	for (UInt32 i = 0; i < inData->mNumberBuffers; i++) {
		memset(inData->mBuffers[i].mData, 0, inData->mBuffers[i].mDataByteSize);
    }
}

@end
